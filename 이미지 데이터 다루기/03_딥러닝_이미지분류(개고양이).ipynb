{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "캐글 자료 다운로드 받기"
      ],
      "metadata": {
        "id": "QOqGZh_DxIow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/overview"
      ],
      "metadata": {
        "id": "AiJOSBebY4hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp2e9JIjXT6a",
        "outputId": "05f2590d-482f-4027-fb34-4a0c7ce9c331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats-redux-kernels-edition.zip to /content\n",
            " 98% 797M/814M [00:10<00:00, 88.1MB/s]\n",
            "100% 814M/814M [00:11<00:00, 77.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "드라이브에 있는 zip 풀기"
      ],
      "metadata": {
        "id": "3Nm70cHcxcUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip -d ."
      ],
      "metadata": {
        "id": "G1f0sI9Avq-V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "8OrEJK8wwnTb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "폴더에 있는 데이터 개수 확인"
      ],
      "metadata": {
        "id": "OgAGSNvuxotX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(len(os.listdir('/content/train')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJWLIabawvsa",
        "outputId": "8111ba59-fafc-4350-ab7b-0a9c101713d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 카테고리 별로 분류"
      ],
      "metadata": {
        "id": "-6FDgt4PbUc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "파일명을 반복해서 출력하는 작업\n",
        "'''\n",
        "\n",
        "import os\n",
        "\n",
        "# print(len(os.listdir('/content/train'/)))\n",
        "\n",
        "for i in os.listdir('/content/train'/):\n",
        "  print(i)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "je4APlkuZrHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "파일명에 따라 카테고리 분류하기\n",
        "'''\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# print(len(os.listdir('/content/train')))\n",
        "\n",
        "for i in os.listdir('/content/train/'):\n",
        "  if 'cat' in i:\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "  if 'dog' in i:\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)\n",
        "\n",
        "print(len(os.listdir('/content/dataset/cat/')))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXWtI8rLZ9kq",
        "outputId": "2122efac-32ea-445d-c1bb-52bebb49e0d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 분류 모델 만들기 전 작업"
      ],
      "metadata": {
        "id": "CKwnXlaJbYau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 훈련 데이터셋 생성\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    # 이미지 파일이 저장된 폴더 경로\n",
        "    '/content/dataset/',\n",
        "    # 모든 이미지를 64x64 크기로 조정\n",
        "    image_size=(64, 64),\n",
        "    # 한 번에 처리할 이미지 수 (batch size)\n",
        "    # batch: 한 번에 처리하는 데이터 묶음. 여기서는 64개의 이미지를 하나의 묶음으로 처리\n",
        "    batch_size=64,\n",
        "    # 데이터 분할 과정:\n",
        "    # 1. validation_split=0.2로 전체 데이터의 20%를 검증용으로 예약\n",
        "    # 2. subset='training'으로 나머지 80%를 훈련 데이터로 선택\n",
        "    subset='training',\n",
        "    validation_split=0.2,\n",
        "    # 데이터 분할 시 일관성 유지를 위한 난수 시드\n",
        "    # 같은 시드를 사용하면 항상 같은 방식으로 데이터가 분할됨\n",
        "    seed=12345\n",
        ")\n",
        "\n",
        "# 검증 데이터셋 생성\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/dataset/',\n",
        "    image_size=(64, 64),\n",
        "    batch_size=64,\n",
        "    # 데이터 분할 과정:\n",
        "    # 1. validation_split=0.2로 전체 데이터의 20%를 검증용으로 예약 (위와 동일)\n",
        "    # 2. subset='validation'으로 예약된 20%를 검증 데이터로 선택\n",
        "    subset='validation',\n",
        "    validation_split=0.2,\n",
        "    seed=12345\n",
        ")\n",
        "\n",
        "print(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBeARKorbapi",
        "outputId": "9b692e73-c7d8-4dea-f41b-bb5c9e8a3f9c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    }
  ]
}